{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/TRELLIS-jupyter/blob/main/TRELLIS_jupyter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjYy0F2gZIPR"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.5.0+cu124 torchvision==0.20.0+cu124 torchaudio==2.5.0+cu124 torchtext==0.18.0 torchdata==0.8.0 --extra-index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install xformers==0.0.28.post2\n",
    "!pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "%cd /content\n",
    "!git clone --recursive https://github.com/Microsoft/TRELLIS\n",
    "%cd /content/TRELLIS\n",
    "\n",
    "!pip install easydict rembg onnxruntime onnxruntime-gpu numpy==2.0.0 plyfile huggingface-hub safetensors\n",
    "!pip install git+https://github.com/NVlabs/nvdiffrast trimesh xatlas pyvista pymeshfix igraph spconv-cu120\n",
    "!pip install opencv-python imageio imageio-ffmpeg ffmpeg-python av\n",
    "!pip install https://github.com/camenduru/wheels/releases/download/3090/kaolin-0.17.0-cp310-cp310-linux_x86_64.whl\n",
    "!pip install https://github.com/camenduru/wheels/releases/download/3090/diso-0.1.4-cp310-cp310-linux_x86_64.whl\n",
    "!pip install https://github.com/camenduru/wheels/releases/download/3090/utils3d-0.0.2-py3-none-any.whl\n",
    "!pip install https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/nvdiffrast-0.3.3-cp310-cp310-linux_x86_64.whl\n",
    "!pip install https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/diff_gaussian_rasterization-0.0.0-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/pipeline.json -d /content/model -o pipeline.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/slat_dec_gs_swin8_B_64l8gs32_fp16.json -d /content/model/ckpts -o slat_dec_gs_swin8_B_64l8gs32_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/slat_dec_gs_swin8_B_64l8gs32_fp16.safetensors -d /content/model/ckpts -o slat_dec_gs_swin8_B_64l8gs32_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/slat_dec_mesh_swin8_B_64l8m256c_fp16.json -d /content/model/ckpts -o slat_dec_mesh_swin8_B_64l8m256c_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/slat_dec_mesh_swin8_B_64l8m256c_fp16.safetensors -d /content/model/ckpts -o slat_dec_mesh_swin8_B_64l8m256c_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/slat_dec_rf_swin8_B_64l8r16_fp16.json -d /content/model/ckpts -o slat_dec_rf_swin8_B_64l8r16_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/slat_dec_rf_swin8_B_64l8r16_fp16.safetensors -d /content/model/ckpts -o slat_dec_rf_swin8_B_64l8r16_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/slat_enc_swin8_B_64l8_fp16.json -d /content/model/ckpts -o slat_enc_swin8_B_64l8_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/slat_enc_swin8_B_64l8_fp16.safetensors -d /content/model/ckpts -o slat_enc_swin8_B_64l8_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/slat_flow_img_dit_L_64l8p2_fp16.json -d /content/model/ckpts -o slat_flow_img_dit_L_64l8p2_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/slat_flow_img_dit_L_64l8p2_fp16.safetensors -d /content/model/ckpts -o slat_flow_img_dit_L_64l8p2_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/ss_dec_conv3d_16l8_fp16.json -d /content/model/ckpts -o ss_dec_conv3d_16l8_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/ss_dec_conv3d_16l8_fp16.safetensors -d /content/model/ckpts -o ss_dec_conv3d_16l8_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/ss_enc_conv3d_16l8_fp16.json -d /content/model/ckpts -o ss_enc_conv3d_16l8_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/ss_enc_conv3d_16l8_fp16.safetensors -d /content/model/ckpts -o ss_enc_conv3d_16l8_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/raw/main/ckpts/ss_flow_img_dit_L_16l8_fp16.json -d /content/model/ckpts -o ss_flow_img_dit_L_16l8_fp16.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/JeffreyXiang/TRELLIS-image-large/resolve/main/ckpts/ss_flow_img_dit_L_16l8_fp16.safetensors -d /content/model/ckpts -o ss_flow_img_dit_L_16l8_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/facebookresearch/dinov2/zipball/main -d /root/.cache/torch/hub -o main.zip\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_reg4_pretrain.pth -d /root/.cache/torch/hub/checkpoints -o dinov2_vitl14_reg4_pretrain.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx -d /root/.u2net -o u2net.onnx\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/facebookresearch/dinov2/zipball/main -d /root/.cache/torch/hub -o main.zip\n",
    "\n",
    "%cd /content/TRELLIS\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "from typing import *\n",
    "from PIL import Image\n",
    "from easydict import EasyDict as edict\n",
    "from trellis.pipelines import TrellisImageTo3DPipeline\n",
    "from trellis.representations import Gaussian, MeshExtractResult\n",
    "from trellis.utils import render_utils, postprocessing_utils\n",
    "\n",
    "MAX_SEED = np.iinfo(np.int32).max\n",
    "TMP_DIR = \"/content\"\n",
    "\n",
    "def preprocess_image(image_path: str) -> Tuple[str, Image.Image]:\n",
    "    trial_id = \"trellis-tost\"\n",
    "    image = Image.open(image_path).convert(\"RGBA\")\n",
    "    processed_image = pipeline.preprocess_image(image)\n",
    "    processed_image.save(f\"{TMP_DIR}/{trial_id}.png\")\n",
    "    return trial_id, processed_image\n",
    "\n",
    "def pack_state(gs: Gaussian, mesh: MeshExtractResult, trial_id: str) -> dict:\n",
    "    return {\n",
    "        'gaussian': {\n",
    "            **gs.init_params,\n",
    "            '_xyz': gs._xyz.cpu().numpy(),\n",
    "            '_features_dc': gs._features_dc.cpu().numpy(),\n",
    "            '_scaling': gs._scaling.cpu().numpy(),\n",
    "            '_rotation': gs._rotation.cpu().numpy(),\n",
    "            '_opacity': gs._opacity.cpu().numpy(),\n",
    "        },\n",
    "        'mesh': {\n",
    "            'vertices': mesh.vertices.cpu().numpy(),\n",
    "            'faces': mesh.faces.cpu().numpy(),\n",
    "        },\n",
    "        'trial_id': trial_id,\n",
    "    }\n",
    "\n",
    "def unpack_state(state: dict) -> Tuple[Gaussian, edict, str]:\n",
    "    gs = Gaussian(\n",
    "        aabb=state['gaussian']['aabb'],\n",
    "        sh_degree=state['gaussian']['sh_degree'],\n",
    "        mininum_kernel_size=state['gaussian']['mininum_kernel_size'],\n",
    "        scaling_bias=state['gaussian']['scaling_bias'],\n",
    "        opacity_bias=state['gaussian']['opacity_bias'],\n",
    "        scaling_activation=state['gaussian']['scaling_activation'],\n",
    "    )\n",
    "    gs._xyz = torch.tensor(state['gaussian']['_xyz'], device='cuda')\n",
    "    gs._features_dc = torch.tensor(state['gaussian']['_features_dc'], device='cuda')\n",
    "    gs._scaling = torch.tensor(state['gaussian']['_scaling'], device='cuda')\n",
    "    gs._rotation = torch.tensor(state['gaussian']['_rotation'], device='cuda')\n",
    "    gs._opacity = torch.tensor(state['gaussian']['_opacity'], device='cuda')\n",
    "\n",
    "    mesh = edict(\n",
    "        vertices=torch.tensor(state['mesh']['vertices'], device='cuda'),\n",
    "        faces=torch.tensor(state['mesh']['faces'], device='cuda'),\n",
    "    )\n",
    "\n",
    "    return gs, mesh, state['trial_id']\n",
    "\n",
    "def image_to_3d(image_path: str, seed: int = 0, randomize_seed: bool = True,\n",
    "                ss_guidance_strength: float = 7.5, ss_sampling_steps: int = 12,\n",
    "                slat_guidance_strength: float = 3.0, slat_sampling_steps: int = 12) -> Tuple[dict, str]:\n",
    "    trial_id, _ = preprocess_image(image_path)\n",
    "    if randomize_seed:\n",
    "        seed = np.random.randint(0, MAX_SEED)\n",
    "\n",
    "    outputs = pipeline.run(\n",
    "        Image.open(f\"{TMP_DIR}/{trial_id}.png\"),\n",
    "        seed=seed,\n",
    "        formats=[\"gaussian\", \"mesh\"],\n",
    "        preprocess_image=False,\n",
    "        sparse_structure_sampler_params={\n",
    "            \"steps\": ss_sampling_steps,\n",
    "            \"cfg_strength\": ss_guidance_strength,\n",
    "        },\n",
    "        slat_sampler_params={\n",
    "            \"steps\": slat_sampling_steps,\n",
    "            \"cfg_strength\": slat_guidance_strength,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    video = render_utils.render_video(outputs['gaussian'][0], num_frames=120)['color']\n",
    "    video_geo = render_utils.render_video(outputs['mesh'][0], num_frames=120)['normal']\n",
    "    video = [np.concatenate([video[i], video_geo[i]], axis=1) for i in range(len(video))]\n",
    "    trial_id = \"trellis-tost\"\n",
    "    video_path = f\"{TMP_DIR}/{trial_id}.mp4\"\n",
    "    imageio.mimsave(video_path, video, fps=15)\n",
    "\n",
    "    state = pack_state(outputs['gaussian'][0], outputs['mesh'][0], str(trial_id))\n",
    "    return state, video_path\n",
    "\n",
    "def extract_glb(state: dict, mesh_simplify: float = 0.95, texture_size: int = 1024) -> str:\n",
    "    gs, mesh, trial_id = unpack_state(state)\n",
    "    glb = postprocessing_utils.to_glb(gs, mesh, simplify=mesh_simplify, texture_size=texture_size, verbose=False)\n",
    "    glb_path = f\"{TMP_DIR}/{trial_id}.glb\"\n",
    "    glb.export(glb_path)\n",
    "    return glb_path\n",
    "\n",
    "with torch.inference_mode():\n",
    "    pipeline = TrellisImageTo3DPipeline.from_pretrained(\"/content/model\")\n",
    "    pipeline.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = \"/content/TRELLIS/T.png\"\n",
    "seed = 0\n",
    "randomize_seed = True\n",
    "ss_guidance_strength = 7.5\n",
    "ss_sampling_steps = 12\n",
    "slat_guidance_strength = 3.0\n",
    "slat_sampling_steps = 12\n",
    "mesh_simplify = 0.95\n",
    "texture_size = 1024\n",
    "\n",
    "state, video_path = image_to_3d(image_path=input_image, \n",
    "                                seed=seed, \n",
    "                                randomize_seed=randomize_seed, \n",
    "                                ss_guidance_strength=ss_guidance_strength, \n",
    "                                ss_sampling_steps=ss_sampling_steps,\n",
    "                                slat_guidance_strength=slat_guidance_strength,\n",
    "                                slat_sampling_steps=slat_sampling_steps)\n",
    "glb_path = extract_glb(state=state, mesh_simplify=mesh_simplify, texture_size=texture_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
